Starting enhanced benchmarks...

===== Testing llama-3.2-1b (Run 1/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 73.63 seconds
Time to first token: 70.62 seconds
Output length: 3053 characters, 394 words
Estimated tokens: 512, 6.96 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing llama-3.2-1b (Run 2/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 73.85 seconds
Time to first token: 70.81 seconds
Output length: 3053 characters, 394 words
Estimated tokens: 512, 6.94 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing llama-3.2-1b (Run 3/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 73.15 seconds
Time to first token: 70.11 seconds
Output length: 3053 characters, 394 words
Estimated tokens: 512, 7.00 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing llama-3.2-1b (Run 1/3) =====
Prompt: Write a short poem about technology....
Total latency: 47.47 seconds
Time to first token: 44.45 seconds
Output length: 2060 characters, 251 words
Estimated tokens: 326, 6.87 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing llama-3.2-1b (Run 2/3) =====
Prompt: Write a short poem about technology....
Total latency: 49.65 seconds
Time to first token: 46.61 seconds
Output length: 2060 characters, 251 words
Estimated tokens: 326, 6.57 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing llama-3.2-1b (Run 3/3) =====
Prompt: Write a short poem about technology....
Total latency: 48.19 seconds
Time to first token: 45.16 seconds
Output length: 2060 characters, 251 words
Estimated tokens: 326, 6.77 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing mistral-7b (Run 1/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 8.44 seconds
Time to first token: 6.36 seconds
Output length: 1077 characters, 102 words
Estimated tokens: 133, 15.71 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing mistral-7b (Run 2/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 8.14 seconds
Time to first token: 6.08 seconds
Output length: 1077 characters, 102 words
Estimated tokens: 133, 16.30 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing mistral-7b (Run 3/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 8.16 seconds
Time to first token: 6.09 seconds
Output length: 1077 characters, 102 words
Estimated tokens: 133, 16.24 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing mistral-7b (Run 1/3) =====
Prompt: Write a short poem about technology....
Total latency: 9.91 seconds
Time to first token: 7.89 seconds
Output length: 1077 characters, 102 words
Estimated tokens: 133, 13.39 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing mistral-7b (Run 2/3) =====
Prompt: Write a short poem about technology....
Total latency: 8.36 seconds
Time to first token: 6.33 seconds
Output length: 1077 characters, 102 words
Estimated tokens: 133, 15.85 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing mistral-7b (Run 3/3) =====
Prompt: Write a short poem about technology....
Total latency: 8.33 seconds
Time to first token: 6.21 seconds
Output length: 1077 characters, 102 words
Estimated tokens: 133, 15.92 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing qwen-1.5-7b (Run 1/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 8.29 seconds
Time to first token: 6.17 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 16.00 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing qwen-1.5-7b (Run 2/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 8.24 seconds
Time to first token: 6.20 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 16.09 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing qwen-1.5-7b (Run 3/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 8.08 seconds
Time to first token: 6.00 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 16.42 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing qwen-1.5-7b (Run 1/3) =====
Prompt: Write a short poem about technology....
Total latency: 8.19 seconds
Time to first token: 6.06 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 16.18 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing qwen-1.5-7b (Run 2/3) =====
Prompt: Write a short poem about technology....
Total latency: 8.28 seconds
Time to first token: 6.17 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 16.01 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing qwen-1.5-7b (Run 3/3) =====
Prompt: Write a short poem about technology....
Total latency: 8.11 seconds
Time to first token: 6.06 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 16.35 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing deepseek-r1 (Run 1/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 8.19 seconds
Time to first token: 6.11 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 16.19 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing deepseek-r1 (Run 2/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 8.21 seconds
Time to first token: 6.10 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 16.16 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing deepseek-r1 (Run 3/3) =====
Prompt: Explain the concept of artificial intelligence in ...
Total latency: 8.39 seconds
Time to first token: 6.30 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 15.81 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing deepseek-r1 (Run 1/3) =====
Prompt: Write a short poem about technology....
Total latency: 8.43 seconds
Time to first token: 6.33 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 15.73 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing deepseek-r1 (Run 2/3) =====
Prompt: Write a short poem about technology....
Total latency: 8.26 seconds
Time to first token: 6.18 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 16.06 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

===== Testing deepseek-r1 (Run 3/3) =====
Prompt: Write a short poem about technology....
Total latency: 8.32 seconds
Time to first token: 6.27 seconds
Output length: 1078 characters, 102 words
Estimated tokens: 133, 15.94 tokens/sec
First 100 chars of output: Selected inference engine: None
[93m
  _____  _____  
 / _ \ \/ / _ \ 
|  __/>  < (_) |
 \___/_/\_\...

Results saved to results/enhanced_benchmark_results_20250407_155112.csv

Model Performance Comparison:
+--------------+---------------------+-------------------+------------------+--------------+-----------------+
| Model        |   Total Latency (s) |   First Token (s) |   Avg Output Len |   Avg Tokens |   Tokens/Second |
+==============+=====================+===================+==================+==============+=================+
| deepseek-r1  |                8.3  |              6.21 |           1078   |       132.6  |           15.98 |
+--------------+---------------------+-------------------+------------------+--------------+-----------------+
| llama-3.2-1b |               60.99 |             57.96 |           2556.5 |       419.25 |            6.85 |
+--------------+---------------------+-------------------+------------------+--------------+-----------------+
| mistral-7b   |                8.56 |              6.49 |           1077   |       132.6  |           15.57 |
+--------------+---------------------+-------------------+------------------+--------------+-----------------+
| qwen-1.5-7b  |                8.2  |              6.11 |           1078   |       132.6  |           16.17 |
+--------------+---------------------+-------------------+------------------+--------------+-----------------+
Comparison table saved to results_benchmarking/enhanced_model_comparison_20250407_155112.txt
Enhanced benchmarking complete!
